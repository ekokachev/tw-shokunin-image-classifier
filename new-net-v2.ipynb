{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from eugenenet.smallvggnetv2 import SmallVGGNet\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:11: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "NUMBER_OF_SAMPLES = 50000\n",
    "\n",
    "TRAIN_DATA_FILE = 'synimg/train/data.csv'\n",
    "# grab the image paths and randomly shuffle them\n",
    "df_imagePaths = pd.DataFrame.from_csv(TRAIN_DATA_FILE)\n",
    "df_imagePaths_sample = df_imagePaths.sample(n=NUMBER_OF_SAMPLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "#aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "#\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,#\n",
    "#\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    " \n",
    "datagen=ImageDataGenerator(rescale=1./255., validation_split=0.15)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42500 validated image filenames belonging to 10 classes.\n",
      "Found 7500 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df_imagePaths_sample,\n",
    "directory=\"./\",\n",
    "x_col=\"filepath\",\n",
    "y_col=\"style_name\",\n",
    "subset=\"training\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(32,64))\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=df_imagePaths_sample,\n",
    "directory=\".\",\n",
    "x_col=\"filepath\",\n",
    "y_col=\"style_name\",\n",
    "subset=\"validation\",\n",
    "batch_size=32,\n",
    "seed=42,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(32,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n"
     ]
    }
   ],
   "source": [
    "# initialize our VGG-like Convolutional Neural Network\n",
    "model = SmallVGGNet.build(width=64, height=32, depth=3, classes=len(train_generator.class_indices))\n",
    "\n",
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    " \n",
    "# initialize the model and optimizer (you'll want to use\n",
    "# binary_crossentropy for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "#H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS, epochs=EPOCHS)\n",
    "\n",
    "#H = model.fit(trainX, trainY, steps_per_epoch=len(trainX) // BS, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 1.7626 - acc: 0.3386 - val_loss: 1.3825 - val_acc: 0.4495\n",
      "Epoch 2/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 1.1881 - acc: 0.5238 - val_loss: 0.9536 - val_acc: 0.6024\n",
      "Epoch 3/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.9513 - acc: 0.6019 - val_loss: 0.8106 - val_acc: 0.6350\n",
      "Epoch 4/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.8535 - acc: 0.6312 - val_loss: 0.8161 - val_acc: 0.6350\n",
      "Epoch 5/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.8181 - acc: 0.6391 - val_loss: 0.7580 - val_acc: 0.6587\n",
      "Epoch 6/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.8016 - acc: 0.6428 - val_loss: 0.7485 - val_acc: 0.6593\n",
      "Epoch 7/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7929 - acc: 0.6477 - val_loss: 0.7571 - val_acc: 0.6535\n",
      "Epoch 8/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7788 - acc: 0.6490 - val_loss: 0.7414 - val_acc: 0.6616\n",
      "Epoch 9/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7708 - acc: 0.6512 - val_loss: 0.7396 - val_acc: 0.6583\n",
      "Epoch 10/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7637 - acc: 0.6538 - val_loss: 0.7318 - val_acc: 0.6652\n",
      "Epoch 11/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7617 - acc: 0.6549 - val_loss: 0.7351 - val_acc: 0.6628\n",
      "Epoch 12/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7534 - acc: 0.6583 - val_loss: 0.7280 - val_acc: 0.6666\n",
      "Epoch 13/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7500 - acc: 0.6581 - val_loss: 0.7221 - val_acc: 0.6660\n",
      "Epoch 14/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7471 - acc: 0.6608 - val_loss: 0.7253 - val_acc: 0.6612\n",
      "Epoch 15/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7426 - acc: 0.6610 - val_loss: 0.7295 - val_acc: 0.6612\n",
      "Epoch 16/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7390 - acc: 0.6645 - val_loss: 0.7190 - val_acc: 0.6664\n",
      "Epoch 17/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7357 - acc: 0.6624 - val_loss: 0.7229 - val_acc: 0.6693\n",
      "Epoch 18/75\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.7341 - acc: 0.6661 - val_loss: 0.7150 - val_acc: 0.6676\n",
      "Epoch 19/75\n",
      "  70/1328 [>.............................] - ETA: 27s - loss: 0.7225 - acc: 0.6696"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "H = model.fit_generator(generator = train_generator, \n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                        validation_data = valid_generator,  \n",
    "                        validation_steps=STEP_SIZE_VALID, \n",
    "                        epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With batch normalisation: \n",
    "* 40 epochs: acc: 0.6613, loss: 0.7873\n",
    "* 65 epochs: acc: ~0.70\n",
    "* 75 epochs: acc: 0.7248\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
